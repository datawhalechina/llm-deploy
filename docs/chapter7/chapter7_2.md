# 推理框架基础功能
现如今，大模型的应用场景越来越多样化，包括 NLP、CV、Audio 等类型的大模型层出不穷，如何让一款框架能够适应这样的场景，并满足开发者与学习者的长期需求呢？在介绍完 7 -1 的内容之后，想必大家对推理框架已经有个大致的了解了。我们可以进一步走进“框架”，站在框架设计者的角度，认识一个完备的框架应该包含哪些功能，并且如何依赖于之前介绍对宏观设计理念和架构完成这些具体功能。

## 7-2-1 支持多模型推理后端
之前也提到过要完成深度学习框架与部署框架解耦和，具体来讲，就是无论深度学习框架如何变更，部署框架自巍然不动。框架需支持多种深度学习框架（如 TensorFlow、PyTorch）和模型格式（如 ONNX、TorchScript、TensorRT），同时允许用户自定义后端（Custom Backend）
框架开发者无需因训练框架不同重建部署环境，而是海纳百川，“插件化”开发模型持久化容器，这样也是出于对未来对考虑，这种“插件”机制确保新框架或硬件出现时，框架可通过扩展完成快速适配。

## 7-2-2 硬件资源支持
首先为基础比较差的小伙伴介绍几个概念
1. 吞吐量：系统在单位时间内处理请求的数量
2. 响应时间：系统对请求做出响应的时间，等于响应时间-请求时间
3. 并行：并行是指系统同时执行多个进程
4. 并发：两个或多个事件在同一时刻发生
对于单用户的系统而言，响应时间可以很好度量系统的性能，这个指标与人对软件性能的主观感受是非常一致的。
> 0.1 秒：让用户感觉到系统在即时响应的界限，这意味着除了显示结果外，不需要专门的反馈。
> 
> 1.0秒是让用户思绪保持连续的界限，虽然用户能够感觉到延迟。正常情况下，不需要对0.1秒~1.0秒的延迟做特别的反馈，但用户会失去直接操作数据的流畅感。
> 
> 10秒：用户就想要在等待期间执行其它任务了，所以必须在任务完成时给出反馈提示。

但是对于多用户系统，如果只有一个用户使用时，平均响应时间是 t，当你有 n 个用户时，由于系统存在并行能力，用户看到的响应时间通常并不是 n*t，往往比这个值小很多，当然，某些特殊情况下也可能比这个值大很多甚至使系统“故障“（死锁）。在资源配置合理的前提下，总的响应时间并不随用户数的增加而线性增加，所以应该用吞吐量来衡量并发系统的性能。

当模型部署到容器中，系统要对请求完成分布式调度，协调请求在硬件资源上的分配，榨干每一块 GPU 或者是 CPU 的性能，以此来降低推理延迟，提升吞吐量。关于并行的部分，我们都知道，Pytorch 是一个拥有很好并行处理能力的深度学习框架，实际上这是由于 Transformer 的能够很好的并行完成任务，其多头注意力机制，保证了每个注意力头都能独立的处理输入的一部分，实现了将数据并行，模型并行；类似的，对于一个多阶段任务，在推理过程中也可以将每一步放到不同硬件上，实现并行。但如果对于任务/模型过度切片，我们还需要考虑通信开销，本质上是一种 trade-off。

## 7-2-3 推理服务请求队列分发和调度
当一个推理请求从 client 端输入进来，部署框架应该有哪些动作，例如对请求的整合？整合完进行分发？
实际上应该想到，由于模型的不同，任务的不同，对于推理请求的处理方式也应该是不同的，其分发调度策略也有所变化。参考 Triton 框架的设计，它把模型分为以下三种类型

1. 无状态模型（Stateless models）：简单来说，对于不同推理请求，它们相互之间没有相互依赖的情况，平时遇到的大部分模型都属于这一类，比如：文本分类、实体抽取、目标检测等
2. 有状态模型（Stateful models）：当前模型输出依赖于上一刻模型的状态
3. 集成模型（Ensemble models）：由多个模型组成工作流，例如 MinerU，通过将多个模型组合，实现对于论文内容的高度提取

Triton 还提供了一个调度器(Scheduler)，可以根据不同的调度策略将推理请求分配到模型实例上执行推理，常见的调度策略有下面几种

1. 默认调度：简单的将推理请求按比例分配
2. 动态调度：将一定时间内的请求聚合成一个批次（batch），但是这种方式只能用于调度无状态的模型。
3. 顺序调度：类似于动态调度，顺序调度也是将推理请求动态聚合，但是顺序调度应用于有状态模型
4. 集成调度：字面意思，只能调度集成模型的请求

## 启发式思考指南
刚介绍了几种推理框架的应该包含的基础功能，但是到网上乍一看，好像大家都有这些功能，那用户应该来如何选择呢，如何判断框架是否完善呢。这一点向来是仁者见仁，因此这里只做一些启发性的引导
1. 计算效率和并行化能力
2. 模块化，插件化和可拓展能力
3. 训练效率和资源利用率：如果使用了分布式训练，是否对通信开销进行分析和处理
4. 最最重要的，用户友好性与详尽的文档：是否提供了一个友好的 api 接口，降低用户对学习曲线，并且一个活跃的社区也有助于提高开发效率
